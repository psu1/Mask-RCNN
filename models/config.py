"""Mask R-CNN config system.
"""

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
from __future__ import unicode_literals

import six
import os
import os.path as osp
import copy
from ast import literal_eval

import numpy as np
import math
import yaml

from utils.collections import AttrDict

__C = AttrDict()

cfg = __C


# ---------------------------------------------------------------------------- #
# Datasset
# ---------------------------------------------------------------------------- #
__C.DATASET = AttrDict()

# PATH TO COCO
__C.DATASET.PATH = ''

#Automatically download and unzip MS-COCO files
__C.DATASET.DOWNLOAD = False

# Year of the MS-COCO dataset (2014 or 2017)
__C.DATASET.YEAR = 2014

# Image mean (RGB)
__C.DATASET.MEAN_PIXEL = np.array([123.7, 116.8, 103.9])

# ---------------------------------------------------------------------------- #
# Training options
# ---------------------------------------------------------------------------- #
__C.TRAIN = AttrDict()

__C.TRAIN.WEIGHTS = ''

__C.TRAIN.STEPS_PER_EPOCH = 1000
__C.TRAIN.VALIDATION_STEPS = 50

# Training schedule in EPOCH
__C.TRAIN.TRAIN_SCHEDULE = [1, 1, 1]

# Maximum number of ground truth instances to use in one image
__C.TRAIN.MAX_GT_INSTANCES = 100

# Input image resing
# Images are resized such that the smallest side is >= IMAGE_MIN_DIM and
# the longest side is <= IMAGE_MAX_DIM. In case both conditions can't
# be satisfied together the IMAGE_MAX_DIM is enforced.
__C.TRAIN.IMAGE_MIN_DIM = 800
__C.TRAIN.IMAGE_MAX_DIM = 1024

# If True, pad images with zeros such that they're (max_dim by max_dim)
__C.TRAIN.IMAGE_PADDING = True  # currently, the False option is not supported


# Max number of final detections
__C.TRAIN.DETECTION_MAX_INSTANCES = 100

# Minimum probability value to accept a detected instance
# ROIs below this threshold are skipped
__C.TRAIN.DETECTION_MIN_CONFIDENCE = 0.7

# Non-maximum suppression threshold for detection
__C.TRAIN.DETECTION_NMS_THRESHOLD = 0.3


# ---------------------------------------------------------------------------- #
# ROIS
# ---------------------------------------------------------------------------- #
__C.ROIS = AttrDict()
__C.ROIS.POOL_SIZE = 7

# Number of ROIs per image to feed to classifier/mask heads
# The Mask RCNN paper uses 512 but often the RPN doesn't generate
# enough positive proposals to fill this and keep a positive:negative
# ratio of 1:3. You can increase the number of proposals by adjusting
# the RPN NMS threshold.
__C.ROIS.NUM_PER_IMAGE = 200

# Percent of positive ROIs used to train classifier/mask heads
__C.ROIS.POSITIVE_RATIO = 0.33

# ROIs kept after non-maximum supression (training)
__C.ROIS.POST_NMS_ROIS = 2000


# ---------------------------------------------------------------------------- #
# Inference options
# ---------------------------------------------------------------------------- #
__C.TEST = AttrDict()

# ROIs kept after non-maximum supression (inference)
__C.TEST.POST_NMS_ROIS = 1000

__C.TEST.GPU_COUNT = 1
__C.TEST.IMAGES_PER_GPU = 1

# Images to use for evaluation (default=500)
__C.TEST.NUM_IMG = 500

# ---------------------------------------------------------------------------- #
# Model options
# ---------------------------------------------------------------------------- #
__C.MODEL = AttrDict()
__C.MODEL.NAME = ''
__C.MODEL.CONV_BODY = ''

# Number of classification classes (including background)
__C.MODEL.NUM_CLASSES = 1 + 80

# ---------------------------------------------------------------------------- #
# Mask-RCNN options
# ---------------------------------------------------------------------------- #
__C.MRCNN = AttrDict()

# Pooled ROIs
__C.MRCNN.POOL_SIZE = 14
__C.MRCNN.MASK_SHAPE = [28, 28]

# If enabled, resizes instance masks to a smaller size to reduce
# memory load. Recommended when using high-resolution images.
__C.MRCNN.USE_MINI_MASK = True
__C.MRCNN.MINI_MASK_SHAPE = (56, 56)  # (height, width) of the mini-mask


# ---------------------------------------------------------------------------- #
# RPN options
# ---------------------------------------------------------------------------- #
__C.RPN = AttrDict()
# Length of square anchor side in pixels
__C.RPN.ANCHOR_SCALES = (32, 64, 128, 256, 512)

# Ratios of anchors at each cell (width/height)
__C.RPN.ANCHOR_RATIOS = [0.5, 1, 2]

# How many anchors per image to use for RPN training
__C.RPN.TRAIN_ANCHORS_PER_IMAGE = 256

# Anchor stride
# If 1 then anchors are created for each cell in the backbone feature map.
# If 2, then anchors are created for every other cell, and so on.
__C.RPN.ANCHOR_STRIDE = 1

# Non-max suppression threshold to filter RPN proposals.
# You can reduce this during training to generate more propsals.
__C.RPN.NMS_THRESHOLD = 0.7

# Use RPN ROIs or externally generated ROIs for training
# Keep this True for most situations. Set to False if you want to train
# the head branches on ROI generated by code rather than the ROIs from
# the RPN. For example, to debug the classifier head without having to
# train the RPN.
__C.RPN.USE_RPN_ROIS = True

# Bounding box refinement standard deviation for RPN and final detections.
__C.RPN.BBOX_STD_DEV = np.array([0.1, 0.1, 0.2, 0.2])

__C.BBOX_STD_DEV = np.array([0.1, 0.1, 0.2, 0.2])


# ---------------------------------------------------------------------------- #
# FPN options
# ---------------------------------------------------------------------------- #
__C.FPN = AttrDict()
# The strides of each layer of the FPN Pyramid. These values
# are based on a Resnet101 backbone.
__C.FPN.BACKBONE_STRIDES = [4, 8, 16, 32, 64]


# ---------------------------------------------------------------------------- #
# Solver options
# ---------------------------------------------------------------------------- #
__C.SOLVER = AttrDict()
__C.SOLVER.BASE_LR = 0.001
__C.SOLVER.MOMENTUM = 0.9
__C.SOLVER.WEIGHT_DECAY = 0.0005


# ---------------------------------------------------------------------------- #
# Misc options
# ---------------------------------------------------------------------------- #
# Number of GPUs to use
__C.GPU_COUNT = 1
__C.IMAGES_PER_GPU = 1

# Root directory of project
__C.ROOT_DIR = os.getcwd()

# For reproducibility
__C.RNG_SEED = 3

# DEMO
__C.DEMO = AttrDict()

__C.DEMO.WEIGHTS = 'pre_train_models/mask_rcnn_coco.pth'

def set_cfg_value():
        """
        Set values of computed attributes.
        """
        __C.TRAIN.LOG_DIR = os.path.join(__C.ROOT_DIR, "logs")
        # demo img dir
        __C.DEMO.IMAGE_DIR = os.path.join(__C.ROOT_DIR, "data/images")
        # Effective batch size
        if __C.GPU_COUNT > 0:
            __C.TRAIN.BATCH_SIZE = __C.IMAGES_PER_GPU * __C.GPU_COUNT
        else:
            __C.TRAIN.BATCH_SIZE = __C.IMAGES_PER_GPU

        # Adjust step size based on batch size
        __C.TRAIN.STEPS_PER_EPOCH = __C.TRAIN.BATCH_SIZE * __C.TRAIN.STEPS_PER_EPOCH

        # Input image size
        __C.TRAIN.IMAGE_SHAPE = np.array(
            [__C.TRAIN.IMAGE_MAX_DIM, __C.TRAIN.IMAGE_MAX_DIM, 3])

        # Compute backbone size from input image size
        __C.FPN.BACKBONE_SHAPES = np.array(
            [[int(math.ceil(__C.TRAIN.IMAGE_SHAPE[0] / stride)),
              int(math.ceil(__C.TRAIN.IMAGE_SHAPE[1] / stride))]
             for stride in __C.FPN.BACKBONE_STRIDES])

def merge_cfg_from_file(cfg_filename):
    """Load a yaml config file and merge it into the global config."""
    with open(cfg_filename, 'r') as f:
        yaml_cfg = AttrDict(yaml.load(f))
    _merge_a_into_b(yaml_cfg, __C)

cfg_from_file = merge_cfg_from_file


def merge_cfg_from_cfg(cfg_other):
    """Merge `cfg_other` into the global config."""
    _merge_a_into_b(cfg_other, __C)


def merge_cfg_from_list(cfg_list):
    """Merge config keys, values in a list (e.g., from command line) into the
    global config. For example, `cfg_list = ['TEST.NMS', 0.5]`.
    """
    assert len(cfg_list) % 2 == 0
    for full_key, v in zip(cfg_list[0::2], cfg_list[1::2]):
        # if _key_is_deprecated(full_key):
        #     continue
        # if _key_is_renamed(full_key):
        #     _raise_key_rename_error(full_key)
        key_list = full_key.split('.')
        d = __C
        for subkey in key_list[:-1]:
            assert subkey in d, 'Non-existent key: {}'.format(full_key)
            d = d[subkey]
        subkey = key_list[-1]
        assert subkey in d, 'Non-existent key: {}'.format(full_key)
        value = _decode_cfg_value(v)
        value = _check_and_coerce_cfg_value_type(
            value, d[subkey], subkey, full_key
        )
        d[subkey] = value

cfg_from_list = merge_cfg_from_list


def _merge_a_into_b(a, b, stack=None):
    """Merge config dictionary a into config dictionary b, clobbering the
    options in b whenever they are also specified in a.
    """
    assert isinstance(a, AttrDict), 'Argument `a` must be an AttrDict'
    assert isinstance(b, AttrDict), 'Argument `b` must be an AttrDict'

    for k, v_ in a.items():
        full_key = '.'.join(stack) + '.' + k if stack is not None else k
        # a must specify keys that are in b
        if k not in b:
            # if _key_is_deprecated(full_key):
            #     continue
            # elif _key_is_renamed(full_key):
            #     _raise_key_rename_error(full_key)
            # else:
            raise KeyError('Non-existent config key: {}'.format(full_key))

        v = copy.deepcopy(v_)
        v = _decode_cfg_value(v)
        v = _check_and_coerce_cfg_value_type(v, b[k], k, full_key)

        # Recursively merge dicts
        if isinstance(v, AttrDict):
            try:
                stack_push = [k] if stack is None else stack + [k]
                _merge_a_into_b(v, b[k], stack=stack_push)
            except BaseException:
                raise
        else:
            b[k] = v


def _decode_cfg_value(v):
    """Decodes a raw config value (e.g., from a yaml config files or command
    line argument) into a Python object.
    """
    # Configs parsed from raw yaml will contain dictionary keys that need to be
    # converted to AttrDict objects
    if isinstance(v, dict):
        return AttrDict(v)
    # All remaining processing is only applied to strings
    if not isinstance(v, six.string_types):
        return v
    # Try to interpret `v` as a:
    #   string, number, tuple, list, dict, boolean, or None
    try:
        v = literal_eval(v)
    # The following two excepts allow v to pass through when it represents a
    # string.
    #
    # Longer explanation:
    # The type of v is always a string (before calling literal_eval), but
    # sometimes it *represents* a string and other times a data structure, like
    # a list. In the case that v represents a string, what we got back from the
    # yaml parser is 'foo' *without quotes* (so, not '"foo"'). literal_eval is
    # ok with '"foo"', but will raise a ValueError if given 'foo'. In other
    # cases, like paths (v = 'foo/bar' and not v = '"foo/bar"'), literal_eval
    # will raise a SyntaxError.
    except ValueError:
        pass
    except SyntaxError:
        pass
    return v


def _check_and_coerce_cfg_value_type(value_a, value_b, key, full_key):
    """Checks that `value_a`, which is intended to replace `value_b` is of the
    right type. The type is correct if it matches exactly or is one of a few
    cases in which the type can be easily coerced.
    """
    # The types must match (with some exceptions)
    type_b = type(value_b)
    type_a = type(value_a)
    if type_a is type_b:
        return value_a

    # Exceptions: numpy arrays, strings, tuple<->list
    if isinstance(value_b, np.ndarray):
        value_a = np.array(value_a, dtype=value_b.dtype)
    elif isinstance(value_b, six.string_types):
        value_a = str(value_a)
    elif isinstance(value_a, tuple) and isinstance(value_b, list):
        value_a = list(value_a)
    elif isinstance(value_a, list) and isinstance(value_b, tuple):
        value_a = tuple(value_a)
    else:
        raise ValueError(
            'Type mismatch ({} vs. {}) with values ({} vs. {}) for config '
            'key: {}'.format(type_b, type_a, value_b, value_a, full_key)
        )
    return value_a